/**
 * Workflow Orchestrator Tests
 */

import { describe, it, expect, vi, beforeEach } from 'vitest';
import { WorkflowOrchestrator, createOrchestrator } from './orchestrator.js';
import type {
  OrchestratorConfig,
  GenerationRequest,
  EditRequest,
} from './types.js';
import type { ILLMService, CompletionResult, ChatMessage } from '../llm/types.js';
import { createSimpleDSL, dslToYAML } from '../generator/generator.js';
import type { DifyDSL } from '../types/index.js';

// Mock LLM Service
class MockLLMService implements ILLMService {
  readonly provider = 'openai' as const;
  private responses: string[] = [];
  private currentIndex = 0;

  constructor(responses: string[] = []) {
    this.responses = responses;
  }

  async chat(_messages: ChatMessage[], _options?: any): Promise<CompletionResult> {
    if (this.currentIndex >= this.responses.length) {
      return {
        content: this.generateDefaultResponse(),
        finishReason: 'stop',
        model: 'gpt-4o',
      };
    }

    const content = this.responses[this.currentIndex++]!;
    return {
      content,
      finishReason: 'stop',
      model: 'gpt-4o',
      usage: {
        promptTokens: 100,
        completionTokens: 200,
        totalTokens: 300,
      },
    };
  }

  async complete(prompt: string, _options?: any): Promise<CompletionResult> {
    return this.chat([{ role: 'user', content: prompt }], _options);
  }

  async isAvailable(): Promise<boolean> {
    return true;
  }

  setResponses(responses: string[]): void {
    this.responses = responses;
    this.currentIndex = 0;
  }

  private generateDefaultResponse(): string {
    const dsl = createSimpleDSL('Test Workflow', 'Generated by mock');
    return dslToYAML(dsl);
  }
}

// Helper to create mock config
function createMockConfig(overrides?: Partial<OrchestratorConfig>): OrchestratorConfig {
  return {
    provider: 'openai',
    apiKey: 'test-key',
    planningModel: 'gpt-4o',
    generationModel: 'gpt-4o',
    verbose: false,
    maxRetries: 2,
    ...overrides,
  };
}

// Mock the LLM module at the top level
let mockLLMInstance: MockLLMService;

vi.mock('../llm/index.js', () => ({
  createLLMService: () => mockLLMInstance,
}));

describe('WorkflowOrchestrator', () => {
  let mockLLM: MockLLMService;
  let orchestrator: WorkflowOrchestrator;

  beforeEach(() => {
    mockLLM = new MockLLMService();
    mockLLMInstance = mockLLM;

    const config = createMockConfig();
    orchestrator = new WorkflowOrchestrator(config);

    // Replace the LLM service with our mock
    (orchestrator as any).llm = mockLLM;
  });

  describe('Constructor', () => {
    it('should create orchestrator with default config', () => {
      const config = createMockConfig();
      const orch = new WorkflowOrchestrator(config);

      expect(orch).toBeDefined();
    });

    it('should use provided config values', () => {
      const config = createMockConfig({
        planningModel: 'gpt-4',
        generationModel: 'gpt-4-turbo',
        maxRetries: 5,
        verbose: true,
      });

      const orch = new WorkflowOrchestrator(config);
      expect(orch).toBeDefined();
    });

    it('should apply default values for missing config', () => {
      const config: OrchestratorConfig = {
        provider: 'openai',
        apiKey: 'test-key',
      };

      const orch = new WorkflowOrchestrator(config);
      expect(orch).toBeDefined();
    });
  });

  describe('Generate Workflow', () => {
    it('should generate a simple workflow successfully', async () => {
      const dsl = createSimpleDSL('QA Workflow', 'Simple QA');
      const yaml = dslToYAML(dsl);

      // Mock planner response (plan)
      const planResponse = JSON.stringify({
        success: true,
        plan: {
          nodes: [
            { id: 'start', type: 'start', title: 'å¼€å§‹' },
            { id: 'llm', type: 'llm', title: 'AIå¤„ç†' },
            { id: 'end', type: 'end', title: 'ç»“æŸ' },
          ],
          edges: [
            { source: 'start', target: 'llm' },
            { source: 'llm', target: 'end' },
          ],
          inputVariables: [{ name: 'input', type: 'string' }],
          outputs: [{ name: 'result', type: 'string' }],
          confidence: 0.9,
        },
      });

      // Mock generation response (DSL YAML)
      const wrappedYaml = `\`\`\`yaml\n${yaml}\n\`\`\``;

      mockLLM.setResponses([planResponse, wrappedYaml]);

      const request: GenerationRequest = {
        prompt: 'åˆ›å»ºä¸€ä¸ªç®€å•çš„é—®ç­”å·¥ä½œæµ',
      };

      const result = await orchestrator.generate(request);

      expect(result.success).toBe(true);
      expect(result.dsl).toBeDefined();
      expect(result.yaml).toBeDefined();
      expect(result.metadata?.duration).toBeDefined();
    });

    it('should handle template matching when not skipped', async () => {
      const request: GenerationRequest = {
        prompt: 'åˆ›å»ºä¸€ä¸ªç®€å•çš„é—®ç­”å¯¹è¯å·¥ä½œæµ',
        skipTemplates: false,
      };

      // Even if template doesn't match well, should fallback to generation
      const dsl = createSimpleDSL('Test', 'Test');
      const yaml = dslToYAML(dsl);

      mockLLM.setResponses([
        JSON.stringify({ success: true, plan: { nodes: [], edges: [], inputVariables: [], outputs: [], confidence: 0.8 } }),
        `\`\`\`yaml\n${yaml}\n\`\`\``,
      ]);

      const result = await orchestrator.generate(request);

      expect(result.success).toBe(true);
    });

    it('should skip templates when requested', async () => {
      const request: GenerationRequest = {
        prompt: 'åˆ›å»ºä¸€ä¸ªé—®ç­”å·¥ä½œæµ',
        skipTemplates: true,
      };

      const dsl = createSimpleDSL('Test', 'Test');
      const yaml = dslToYAML(dsl);

      mockLLM.setResponses([
        JSON.stringify({ success: true, plan: { nodes: [], edges: [], inputVariables: [], outputs: [], confidence: 0.9 } }),
        `\`\`\`yaml\n${yaml}\n\`\`\``,
      ]);

      const result = await orchestrator.generate(request);

      expect(result.success).toBe(true);
    });

    it('should include metadata with duration', async () => {
      const dsl = createSimpleDSL('Test', 'Test');
      const yaml = dslToYAML(dsl);

      mockLLM.setResponses([
        JSON.stringify({ success: true, plan: { nodes: [], edges: [], inputVariables: [], outputs: [], confidence: 0.9 } }),
        `\`\`\`yaml\n${yaml}\n\`\`\``,
      ]);

      const request: GenerationRequest = {
        prompt: 'åˆ›å»ºå·¥ä½œæµ',
      };

      const result = await orchestrator.generate(request);

      expect(result.metadata).toBeDefined();
      expect(result.metadata?.duration).toBeGreaterThanOrEqual(0);
    });

    it('should pass preferred provider and model', async () => {
      const dsl = createSimpleDSL('Test', 'Test');
      const yaml = dslToYAML(dsl);

      mockLLM.setResponses([
        JSON.stringify({ success: true, plan: { nodes: [], edges: [], inputVariables: [], outputs: [], confidence: 0.9 } }),
        `\`\`\`yaml\n${yaml}\n\`\`\``,
      ]);

      const request: GenerationRequest = {
        prompt: 'åˆ›å»ºå·¥ä½œæµ',
        preferredProvider: 'anthropic',
        preferredModel: 'claude-3-opus',
      };

      const result = await orchestrator.generate(request);

      expect(result.success).toBe(true);
    });

    it('should handle dataset IDs', async () => {
      const dsl = createSimpleDSL('Test', 'Test');
      const yaml = dslToYAML(dsl);

      mockLLM.setResponses([
        JSON.stringify({ success: true, plan: { nodes: [], edges: [], inputVariables: [], outputs: [], confidence: 0.9 } }),
        `\`\`\`yaml\n${yaml}\n\`\`\``,
      ]);

      const request: GenerationRequest = {
        prompt: 'åˆ›å»ºçŸ¥è¯†åº“é—®ç­”å·¥ä½œæµ',
        datasetIds: ['dataset-1', 'dataset-2'],
      };

      const result = await orchestrator.generate(request);

      expect(result.success).toBe(true);
    });
  });

  describe('Generate Error Handling', () => {
    it('should return error when planning fails', async () => {
      mockLLM.setResponses([
        JSON.stringify({ success: false, error: 'Planning failed' }),
      ]);

      const request: GenerationRequest = {
        prompt: 'åˆ›å»ºå·¥ä½œæµ',
      };

      const result = await orchestrator.generate(request);

      expect(result.success).toBe(false);
      expect(result.error).toBeDefined();
    });

    it('should handle YAML extraction failure', async () => {
      mockLLM.setResponses([
        JSON.stringify({ success: true, plan: { nodes: [], edges: [], inputVariables: [], outputs: [], confidence: 0.9 } }),
        'This is not YAML at all, just random text',
      ]);

      const request: GenerationRequest = {
        prompt: 'åˆ›å»ºå·¥ä½œæµ',
      };

      const result = await orchestrator.generate(request);

      expect(result.success).toBe(false);
      expect(result.error).toContain('Failed to extract YAML');
    });

    it('should handle YAML parse errors', async () => {
      mockLLM.setResponses([
        JSON.stringify({ success: true, plan: { nodes: [], edges: [], inputVariables: [], outputs: [], confidence: 0.9 } }),
        '```yaml\ninvalid: yaml: content: {{{\n```',
      ]);

      const request: GenerationRequest = {
        prompt: 'åˆ›å»ºå·¥ä½œæµ',
      };

      const result = await orchestrator.generate(request);

      expect(result.success).toBe(false);
      expect(result.error).toBeDefined();
    });

    it('should retry on validation errors', async () => {
      // Invalid DSL (missing start node)
      const invalidDsl: DifyDSL = {
        version: '0.5.0',
        kind: 'app',
        app: { name: 'Test', mode: 'workflow', icon: 'ðŸ¤–', icon_type: 'emoji' },
        workflow: {
          graph: {
            nodes: [
              {
                id: 'end',
                type: 'custom',
                data: { type: 'end', title: 'ç»“æŸ', outputs: [] },
              },
            ],
            edges: [],
          },
        },
      };

      const invalidYaml = dslToYAML(invalidDsl);
      const validDsl = createSimpleDSL('Fixed', 'Fixed workflow');
      const validYaml = dslToYAML(validDsl);

      mockLLM.setResponses([
        JSON.stringify({ success: true, plan: { nodes: [], edges: [], inputVariables: [], outputs: [], confidence: 0.9 } }),
        `\`\`\`yaml\n${invalidYaml}\n\`\`\``,
        `\`\`\`yaml\n${validYaml}\n\`\`\``,
      ]);

      const request: GenerationRequest = {
        prompt: 'åˆ›å»ºå·¥ä½œæµ',
      };

      const result = await orchestrator.generate(request);

      expect(result.success).toBe(true);
    });

    it('should fail after max retries on validation errors', async () => {
      const invalidDsl: DifyDSL = {
        version: '0.5.0',
        kind: 'app',
        app: { name: 'Test', mode: 'workflow', icon: 'ðŸ¤–', icon_type: 'emoji' },
        workflow: {
          graph: { nodes: [], edges: [] },
        },
      };

      const invalidYaml = dslToYAML(invalidDsl);

      mockLLM.setResponses([
        JSON.stringify({ success: true, plan: { nodes: [], edges: [], inputVariables: [], outputs: [], confidence: 0.9 } }),
        `\`\`\`yaml\n${invalidYaml}\n\`\`\``,
        `\`\`\`yaml\n${invalidYaml}\n\`\`\``,
        `\`\`\`yaml\n${invalidYaml}\n\`\`\``,
        `\`\`\`yaml\n${invalidYaml}\n\`\`\``,
      ]);

      const request: GenerationRequest = {
        prompt: 'åˆ›å»ºå·¥ä½œæµ',
      };

      const result = await orchestrator.generate(request);

      expect(result.success).toBe(false);
      expect(result.error).toContain('Failed to fix');
    });

    it('should handle exceptions gracefully', async () => {
      // Mock LLM that throws errors
      const errorLLM = new MockLLMService();
      (orchestrator as any).llm = errorLLM;

      vi.spyOn(errorLLM, 'chat').mockRejectedValue(new Error('LLM service unavailable'));

      const request: GenerationRequest = {
        prompt: 'åˆ›å»ºå·¥ä½œæµ',
      };

      const result = await orchestrator.generate(request);

      expect(result.success).toBe(false);
      expect(result.error).toBeDefined();
      expect(result.metadata?.duration).toBeDefined();
    });
  });

  describe('Edit Workflow', () => {
    it('should edit an existing workflow successfully', async () => {
      const currentDsl = createSimpleDSL('Original', 'Original description');
      const editedDsl = createSimpleDSL('Edited', 'Edited description');
      const editedYaml = dslToYAML(editedDsl);

      mockLLM.setResponses([`\`\`\`yaml\n${editedYaml}\n\`\`\``]);

      const request: EditRequest = {
        currentDsl,
        instruction: 'ä¿®æ”¹å·¥ä½œæµåç§°ä¸º Edited',
      };

      const result = await orchestrator.edit(request);

      expect(result.success).toBe(true);
      expect(result.dsl).toBeDefined();
      expect(result.yaml).toBeDefined();
    });

    it('should detect changes between old and new DSL', async () => {
      const currentDsl = createSimpleDSL('Original', 'Original');

      // Create edited DSL with an additional node
      const editedDsl = createSimpleDSL('Edited', 'Edited');
      const newNodeId = 'new-node-123';

      editedDsl.workflow?.graph.nodes.push({
        id: newNodeId,
        type: 'custom',
        data: {
          type: 'llm',
          title: 'New LLM',
          model: { provider: 'openai', name: 'gpt-4o', mode: 'chat' },
          prompt_template: [{ role: 'user', text: 'test' }],
        },
      });

      const editedYaml = dslToYAML(editedDsl);

      mockLLM.setResponses([`\`\`\`yaml\n${editedYaml}\n\`\`\``]);

      const request: EditRequest = {
        currentDsl,
        instruction: 'æ·»åŠ ä¸€ä¸ªæ–°çš„ LLM èŠ‚ç‚¹',
      };

      const result = await orchestrator.edit(request);

      expect(result.success).toBe(true);
      expect(result.changes).toBeDefined();
      expect(result.changes?.length).toBeGreaterThan(0);
    });

    it('should support targeting specific nodes', async () => {
      const currentDsl = createSimpleDSL('Test', 'Test');
      const editedDsl = createSimpleDSL('Test', 'Test');
      const editedYaml = dslToYAML(editedDsl);

      mockLLM.setResponses([`\`\`\`yaml\n${editedYaml}\n\`\`\``]);

      const request: EditRequest = {
        currentDsl,
        instruction: 'ä¿®æ”¹ LLM èŠ‚ç‚¹çš„æç¤ºè¯',
        targetNodes: ['llm-node-id'],
      };

      const result = await orchestrator.edit(request);

      expect(result.success).toBe(true);
    });

    it('should handle YAML extraction failure in edit', async () => {
      const currentDsl = createSimpleDSL('Test', 'Test');

      mockLLM.setResponses(['No YAML here, just text']);

      const request: EditRequest = {
        currentDsl,
        instruction: 'ä¿®æ”¹å·¥ä½œæµ',
      };

      const result = await orchestrator.edit(request);

      expect(result.success).toBe(false);
      expect(result.error).toContain('Failed to extract YAML');
    });

    it('should handle parse errors in edit', async () => {
      const currentDsl = createSimpleDSL('Test', 'Test');

      mockLLM.setResponses(['```yaml\ninvalid: yaml: {{{{\n```']);

      const request: EditRequest = {
        currentDsl,
        instruction: 'ä¿®æ”¹å·¥ä½œæµ',
      };

      const result = await orchestrator.edit(request);

      expect(result.success).toBe(false);
      expect(result.error).toContain('Parse error');
    });

    it('should retry on validation errors in edit', async () => {
      const currentDsl = createSimpleDSL('Test', 'Test');

      const invalidDsl: DifyDSL = {
        version: '0.5.0',
        kind: 'app',
        app: { name: 'Test', mode: 'workflow', icon: 'ðŸ¤–', icon_type: 'emoji' },
        workflow: {
          graph: { nodes: [], edges: [] },
        },
      };

      const invalidYaml = dslToYAML(invalidDsl);
      const validDsl = createSimpleDSL('Fixed', 'Fixed');
      const validYaml = dslToYAML(validDsl);

      mockLLM.setResponses([
        `\`\`\`yaml\n${invalidYaml}\n\`\`\``,
        `\`\`\`yaml\n${validYaml}\n\`\`\``,
      ]);

      const request: EditRequest = {
        currentDsl,
        instruction: 'ä¿®æ”¹å·¥ä½œæµ',
      };

      const result = await orchestrator.edit(request);

      expect(result.success).toBe(true);
    });

    it('should handle exceptions in edit', async () => {
      const currentDsl = createSimpleDSL('Test', 'Test');

      vi.spyOn(mockLLM, 'chat').mockRejectedValue(new Error('Network error'));

      const request: EditRequest = {
        currentDsl,
        instruction: 'ä¿®æ”¹å·¥ä½œæµ',
      };

      const result = await orchestrator.edit(request);

      expect(result.success).toBe(false);
      expect(result.error).toBeDefined();
    });
  });

  describe('YAML Extraction', () => {
    it('should extract YAML from code blocks with yaml marker', () => {
      const dsl = createSimpleDSL('Test', 'Test');
      const yaml = dslToYAML(dsl);
      const content = `\`\`\`yaml\n${yaml}\n\`\`\``;

      mockLLM.setResponses([
        JSON.stringify({ success: true, plan: { nodes: [], edges: [], inputVariables: [], outputs: [], confidence: 0.9 } }),
        content,
      ]);

      const request: GenerationRequest = { prompt: 'test' };

      return orchestrator.generate(request).then((result) => {
        expect(result.success).toBe(true);
      });
    });

    it('should extract YAML from code blocks with yml marker', () => {
      const dsl = createSimpleDSL('Test', 'Test');
      const yaml = dslToYAML(dsl);
      const content = `\`\`\`yml\n${yaml}\n\`\`\``;

      mockLLM.setResponses([
        JSON.stringify({ success: true, plan: { nodes: [], edges: [], inputVariables: [], outputs: [], confidence: 0.9 } }),
        content,
      ]);

      const request: GenerationRequest = { prompt: 'test' };

      return orchestrator.generate(request).then((result) => {
        expect(result.success).toBe(true);
      });
    });

    it('should extract YAML that starts with version directly', () => {
      const dsl = createSimpleDSL('Test', 'Test');
      const yaml = dslToYAML(dsl);

      mockLLM.setResponses([
        JSON.stringify({ success: true, plan: { nodes: [], edges: [], inputVariables: [], outputs: [], confidence: 0.9 } }),
        yaml,
      ]);

      const request: GenerationRequest = { prompt: 'test' };

      return orchestrator.generate(request).then((result) => {
        expect(result.success).toBe(true);
      });
    });

    it('should handle YAML with surrounding text', () => {
      const dsl = createSimpleDSL('Test', 'Test');
      const yaml = dslToYAML(dsl);
      const content = `Here is your workflow:\n\n${yaml}\n\nLet me know if you need changes.`;

      mockLLM.setResponses([
        JSON.stringify({ success: true, plan: { nodes: [], edges: [], inputVariables: [], outputs: [], confidence: 0.9 } }),
        content,
      ]);

      const request: GenerationRequest = { prompt: 'test' };

      return orchestrator.generate(request).then((result) => {
        expect(result.success).toBe(true);
      });
    });
  });

  describe('createOrchestrator', () => {
    it('should create orchestrator instance', () => {
      const config = createMockConfig();
      const orch = createOrchestrator(config);

      expect(orch).toBeDefined();
      expect(orch).toBeInstanceOf(WorkflowOrchestrator);
    });
  });

  describe('Fix Suggestions', () => {
    it('should generate appropriate suggestions for common errors', async () => {
      const invalidDsl: DifyDSL = {
        version: '0.5.0',
        kind: 'app',
        app: { name: 'Test', mode: 'workflow', icon: 'ðŸ¤–', icon_type: 'emoji' },
        workflow: {
          graph: {
            nodes: [
              {
                id: 'node1',
                type: 'custom',
                data: { type: 'llm', title: 'LLM', model: { provider: 'openai', name: 'gpt-4o', mode: 'chat' }, prompt_template: [] },
              },
            ],
            edges: [
              {
                id: 'e1',
                source: 'nonexistent',
                target: 'node1',
                sourceHandle: 'source',
                targetHandle: 'target',
                type: 'custom',
                data: { sourceType: 'start', targetType: 'llm', isInIteration: false },
              },
            ],
          },
        },
      };

      const invalidYaml = dslToYAML(invalidDsl);

      // Should detect and try to fix
      mockLLM.setResponses([
        JSON.stringify({ success: true, plan: { nodes: [], edges: [], inputVariables: [], outputs: [], confidence: 0.9 } }),
        `\`\`\`yaml\n${invalidYaml}\n\`\`\``,
        `\`\`\`yaml\n${invalidYaml}\n\`\`\``,
        `\`\`\`yaml\n${invalidYaml}\n\`\`\``,
      ]);

      const request: GenerationRequest = { prompt: 'test' };

      const result = await orchestrator.generate(request);

      // Should fail after retries
      expect(result.success).toBe(false);
    });
  });

  describe('Verbose Logging', () => {
    it('should log when verbose is enabled', async () => {
      const consoleSpy = vi.spyOn(console, 'log').mockImplementation(() => {});

      const verboseConfig = createMockConfig({ verbose: true });
      const verboseOrch = new WorkflowOrchestrator(verboseConfig);
      (verboseOrch as any).llm = mockLLM;

      const dsl = createSimpleDSL('Test', 'Test');
      const yaml = dslToYAML(dsl);

      mockLLM.setResponses([
        JSON.stringify({ success: true, plan: { nodes: [], edges: [], inputVariables: [], outputs: [], confidence: 0.9 } }),
        `\`\`\`yaml\n${yaml}\n\`\`\``,
      ]);

      const request: GenerationRequest = { prompt: 'test' };

      await verboseOrch.generate(request);

      expect(consoleSpy).toHaveBeenCalled();

      consoleSpy.mockRestore();
    });

    it('should not log when verbose is disabled', async () => {
      const consoleSpy = vi.spyOn(console, 'log').mockImplementation(() => {});

      const config = createMockConfig({ verbose: false });
      const orch = new WorkflowOrchestrator(config);
      (orch as any).llm = mockLLM;

      const dsl = createSimpleDSL('Test', 'Test');
      const yaml = dslToYAML(dsl);

      mockLLM.setResponses([
        JSON.stringify({ success: true, plan: { nodes: [], edges: [], inputVariables: [], outputs: [], confidence: 0.9 } }),
        `\`\`\`yaml\n${yaml}\n\`\`\``,
      ]);

      const request: GenerationRequest = { prompt: 'test' };

      await orch.generate(request);

      // Should not log orchestrator messages
      const orchestratorLogs = consoleSpy.mock.calls.filter(
        (call) => call[0] && String(call[0]).includes('[Orchestrator]')
      );

      expect(orchestratorLogs.length).toBe(0);

      consoleSpy.mockRestore();
    });
  });
});
