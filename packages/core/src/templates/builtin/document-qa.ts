/**
 * Document Q&A Template
 */

import { createWorkflow } from '../../builder/index.js';
import type { WorkflowTemplate } from '../types.js';

export const documentQATemplate: WorkflowTemplate = {
  metadata: {
    id: 'document-qa',
    name: 'æ–‡æ¡£é—®ç­”ç³»ç»Ÿ',
    description: 'é’ˆå¯¹é•¿æ–‡æ¡£çš„æ™ºèƒ½é—®ç­”ï¼Œæ”¯æŒæ–‡æ¡£æ‘˜è¦ã€å…³é”®ä¿¡æ¯æå–å’Œå¤šè½®å¯¹è¯',
    category: 'rag',
    tags: ['æ–‡æ¡£', 'é—®ç­”', 'RAG', 'æ‘˜è¦'],
    keywords: [
      'æ–‡æ¡£é—®ç­”', 'æ–‡æ¡£åˆ†æ', 'é—®æ–‡æ¡£', 'document qa',
      'PDF', 'é•¿æ–‡æœ¬', 'æ–‡æ¡£æ‘˜è¦', 'ä¿¡æ¯æå–',
      'è¯»æ–‡æ¡£', 'æ–‡æ¡£ç†è§£', 'åˆåŒåˆ†æ',
    ],
    nodeTypes: ['start', 'document-extractor', 'knowledge-retrieval', 'llm', 'if-else', 'variable-aggregator', 'end'],
    complexity: 3,
  },

  build: (params = {}) => {
    const model = (params['model'] as string) ?? 'gpt-4o';
    const provider = (params['provider'] as string) ?? 'openai';
    const enableSummary = (params['enableSummary'] as boolean) ?? true;

    const builder = createWorkflow({
      name: 'æ–‡æ¡£é—®ç­”ç³»ç»Ÿ',
      description: 'æ™ºèƒ½æ–‡æ¡£åˆ†æå’Œé—®ç­”ç³»ç»Ÿ',
      icon: 'ğŸ“„',
    })
      .addStart({
        variables: [
          {
            name: 'document',
            label: 'æ–‡æ¡£å†…å®¹',
            type: 'paragraph',
            required: true,
            maxLength: 100000,
          },
          {
            name: 'question',
            label: 'é—®é¢˜',
            type: 'paragraph',
            required: true,
            maxLength: 2000,
          },
          {
            name: 'question_type',
            label: 'é—®é¢˜ç±»å‹ï¼ˆå¯é€‰ï¼‰',
            type: 'select',
            required: false,
            options: [
              'äº‹å®æŸ¥è¯¢',
              'ä¿¡æ¯æå–',
              'æ–‡æ¡£æ‘˜è¦',
              'å¯¹æ¯”åˆ†æ',
              'æ¨ç†åˆ¤æ–­',
            ],
          },
        ],
      })
      // æ–‡æ¡£é¢„å¤„ç†å’Œåˆ†æ®µ
      .addLLM({
        id: 'preprocess-document',
        title: 'æ–‡æ¡£é¢„å¤„ç†',
        provider,
        model: 'gpt-4o-mini',
        temperature: 0.2,
        systemPrompt: `ä½ æ˜¯æ–‡æ¡£å¤„ç†ä¸“å®¶ã€‚åˆ†ææ–‡æ¡£ç»“æ„å¹¶æå–å…³é”®ä¿¡æ¯ã€‚

è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰ï¼š
{
  "document_type": "æŠ€æœ¯æ–‡æ¡£/åˆåŒ/æŠ¥å‘Š/æ–‡ç« /å…¶ä»–",
  "key_sections": ["ç« èŠ‚1", "ç« èŠ‚2"],
  "entities": ["å®ä½“1", "å®ä½“2"],
  "summary": "æ–‡æ¡£ç®€è¦æ¦‚è¿°ï¼ˆ50å­—å†…ï¼‰"
}`,
        userPrompt: `æ–‡æ¡£å†…å®¹ï¼š
{{#start.document#}}`,
      })
      // åˆ¤æ–­æ˜¯å¦éœ€è¦æ–‡æ¡£æ‘˜è¦
      .addIfElse({
        id: 'check-need-summary',
        title: 'æ£€æŸ¥æ˜¯å¦éœ€è¦æ‘˜è¦',
        conditions: [
          {
            id: 'need-summary',
            logicalOperator: 'or',
            rules: [
              {
                variableSelector: ['start', 'question_type'],
                operator: 'contains',
                value: 'æ‘˜è¦',
              },
            ],
          },
        ],
      })
      // ç”Ÿæˆæ–‡æ¡£æ‘˜è¦
      .addLLM({
        id: 'generate-summary',
        title: 'ç”Ÿæˆæ–‡æ¡£æ‘˜è¦',
        provider,
        model,
        temperature: 0.5,
        systemPrompt: `ä½ æ˜¯ä¸“ä¸šçš„æ–‡æ¡£æ‘˜è¦ä¸“å®¶ã€‚ç”Ÿæˆç»“æ„åŒ–çš„æ–‡æ¡£æ‘˜è¦ã€‚

æ‘˜è¦åº”åŒ…æ‹¬ï¼š
1. æ ¸å¿ƒä¸»é¢˜
2. å…³é”®è¦ç‚¹ï¼ˆ3-5 æ¡ï¼‰
3. é‡è¦æ•°æ®å’Œç»“è®º
4. æ–‡æ¡£ä»·å€¼å’Œé€‚ç”¨åœºæ™¯

ä½¿ç”¨ Markdown æ ¼å¼ï¼Œå±‚æ¬¡æ¸…æ™°ã€‚`,
        userPrompt: `æ–‡æ¡£ç±»å‹ï¼š{{#preprocess-document.text#}}

å®Œæ•´æ–‡æ¡£ï¼š
{{#start.document#}}`,
      });

    // æ™ºèƒ½æ£€ç´¢ç›¸å…³æ®µè½
    if (enableSummary) {
      builder.addLLM({
        id: 'extract-relevant-sections',
        title: 'æå–ç›¸å…³æ®µè½',
        provider,
        model: 'gpt-4o-mini',
        temperature: 0.2,
        systemPrompt: `ä½ æ˜¯ä¿¡æ¯æ£€ç´¢ä¸“å®¶ã€‚ä»æ–‡æ¡£ä¸­æå–ä¸é—®é¢˜æœ€ç›¸å…³çš„æ®µè½ã€‚

è¦æ±‚ï¼š
1. æå– 2-5 ä¸ªæœ€ç›¸å…³çš„æ®µè½
2. ä¿æŒåŸæ–‡ï¼Œä¸è¦æ”¹å†™
3. å¦‚æœæ•´ä¸ªæ–‡æ¡£éƒ½ç›¸å…³ï¼Œè¯´æ˜åŸå› 
4. å¦‚æœæ‰¾ä¸åˆ°ç›¸å…³å†…å®¹ï¼Œæ˜ç¡®æŒ‡å‡º`,
        userPrompt: `æ–‡æ¡£ï¼š
{{#start.document#}}

é—®é¢˜ï¼š{{#start.question#}}

æ–‡æ¡£ç»“æ„ä¿¡æ¯ï¼š{{#preprocess-document.text#}}`,
      });
    }

    builder
      // åˆ†æé—®é¢˜ç±»å‹å’Œæ„å›¾
      .addLLM({
        id: 'analyze-question',
        title: 'åˆ†æé—®é¢˜æ„å›¾',
        provider,
        model: 'gpt-4o-mini',
        temperature: 0.3,
        systemPrompt: `åˆ†æç”¨æˆ·é—®é¢˜çš„ç±»å‹å’Œæ„å›¾ã€‚

è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰ï¼š
{
  "question_type": "äº‹å®æŸ¥è¯¢/ä¿¡æ¯æå–/å¯¹æ¯”åˆ†æ/æ¨ç†åˆ¤æ–­/å¼€æ”¾è®¨è®º",
  "key_focuses": ["ç„¦ç‚¹1", "ç„¦ç‚¹2"],
  "needs_reasoning": true/false,
  "expected_answer_format": "æè¿°"
}`,
        userPrompt: `é—®é¢˜ï¼š{{#start.question#}}
æ–‡æ¡£ç±»å‹ï¼š{{#preprocess-document.text#}}`,
      })
      // ç”Ÿæˆç²¾å‡†ç­”æ¡ˆ
      .addLLM({
        id: 'generate-answer',
        title: 'ç”Ÿæˆç­”æ¡ˆ',
        provider,
        model,
        temperature: 0.5,
        systemPrompt: `ä½ æ˜¯ä¸“ä¸šçš„æ–‡æ¡£åˆ†æå¸ˆã€‚åŸºäºæ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ã€‚

å›ç­”åŸåˆ™ï¼š
1. åªåŸºäºæ–‡æ¡£å†…å®¹ï¼Œä¸è¦ç¼–é€ 
2. æ˜ç¡®åŒºåˆ†äº‹å®å’Œæ¨æ–­
3. å¼•ç”¨å…·ä½“æ®µè½æˆ–ä½ç½®
4. å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯šå®è¯´æ˜
5. å¯¹äºå¤æ‚é—®é¢˜ï¼Œåˆ†æ­¥éª¤è§£é‡Š
6. å¿…è¦æ—¶ä½¿ç”¨è¡¨æ ¼æˆ–åˆ—è¡¨

å¼•ç”¨æ ¼å¼ï¼šæ ¹æ®æ–‡æ¡£ç¬¬Xéƒ¨åˆ†ï¼Œ"åŸæ–‡å¼•ç”¨"...`,
        userPrompt: `æ–‡æ¡£å†…å®¹ï¼š
{{#start.document#}}

ç›¸å…³æ®µè½ï¼š
{{#extract-relevant-sections.text#}}

é—®é¢˜ï¼š{{#start.question#}}

é—®é¢˜åˆ†æï¼š{{#analyze-question.text#}}

è¯·æä¾›å‡†ç¡®ã€æœ‰æ®çš„å›ç­”ã€‚`,
      })
      // ç­”æ¡ˆè´¨é‡è¯„ä¼°
      .addLLM({
        id: 'evaluate-answer',
        title: 'ç­”æ¡ˆè´¨é‡è¯„ä¼°',
        provider,
        model: 'gpt-4o-mini',
        temperature: 0.2,
        systemPrompt: `è¯„ä¼°ç­”æ¡ˆçš„è´¨é‡å’Œå®Œæ•´æ€§ã€‚

è¯„ä¼°ç»´åº¦ï¼š
1. å‡†ç¡®æ€§ï¼ˆæ˜¯å¦åŸºäºæ–‡æ¡£äº‹å®ï¼‰
2. å®Œæ•´æ€§ï¼ˆæ˜¯å¦å……åˆ†å›ç­”é—®é¢˜ï¼‰
3. æ¸…æ™°åº¦ï¼ˆè¡¨è¾¾æ˜¯å¦æ¸…æ¥šï¼‰
4. å¼•ç”¨è´¨é‡ï¼ˆæ˜¯å¦æœ‰æ•ˆå¼•ç”¨ï¼‰

è¾“å‡ºæ ¼å¼ï¼š
- è¯„åˆ†ï¼šX/10
- ä¼˜ç‚¹ï¼š...
- ä¸è¶³ï¼š...
- æ˜¯å¦å»ºè®®è¡¥å……ä¿¡æ¯ï¼šæ˜¯/å¦`,
        userPrompt: `åŸå§‹é—®é¢˜ï¼š{{#start.question#}}

ç”Ÿæˆçš„ç­”æ¡ˆï¼š
{{#generate-answer.text#}}

æ–‡æ¡£å†…å®¹ï¼š
{{#start.document#}}`,
      })
      // å¯é€‰ï¼šç”Ÿæˆåç»­é—®é¢˜å»ºè®®
      .addLLM({
        id: 'suggest-followup',
        title: 'å»ºè®®åç»­é—®é¢˜',
        provider,
        model: 'gpt-4o-mini',
        temperature: 0.7,
        systemPrompt: `åŸºäºå½“å‰é—®ç­”ï¼Œå»ºè®® 3-5 ä¸ªæœ‰ä»·å€¼çš„åç»­é—®é¢˜ã€‚

è¿™äº›é—®é¢˜åº”è¯¥ï¼š
1. æ·±å…¥æŒ–æ˜ç›¸å…³ä¸»é¢˜
2. æ¢ç´¢æ–‡æ¡£çš„å…¶ä»–é‡è¦æ–¹é¢
3. å¸®åŠ©ç”¨æˆ·æ›´å…¨é¢ç†è§£æ–‡æ¡£

ç›´æ¥è¾“å‡ºé—®é¢˜åˆ—è¡¨ï¼Œæ¯è¡Œä¸€ä¸ªé—®é¢˜ã€‚`,
        userPrompt: `æ–‡æ¡£ç±»å‹ï¼š{{#preprocess-document.text#}}

å·²å›ç­”é—®é¢˜ï¼š{{#start.question#}}

ç­”æ¡ˆï¼š{{#generate-answer.text#}}`,
      })
      // èšåˆæœ€ç»ˆç»“æœ
      .addAggregator({
        id: 'final-result',
        title: 'ç»“æœèšåˆ',
        variables: [
          ['generate-summary', 'text'],
          ['generate-answer', 'text'],
        ],
        outputType: 'string',
      })
      .addEnd({
        id: 'end',
        outputs: [
          { name: 'answer', source: ['generate-answer', 'text'] },
          { name: 'document_summary', source: ['generate-summary', 'text'] },
          { name: 'quality_assessment', source: ['evaluate-answer', 'text'] },
          { name: 'followup_questions', source: ['suggest-followup', 'text'] },
          { name: 'relevant_sections', source: ['extract-relevant-sections', 'text'] },
        ],
      });

    // è¿æ¥èŠ‚ç‚¹
    builder
      .connect('start', 'preprocess-document')
      .connect('preprocess-document', 'check-need-summary')
      .connect('check-need-summary', 'generate-summary', { sourceHandle: 'true' })
      .connect('preprocess-document', 'extract-relevant-sections')
      .connect('preprocess-document', 'analyze-question')
      .connect('extract-relevant-sections', 'generate-answer')
      .connect('analyze-question', 'generate-answer')
      .connect('generate-answer', 'evaluate-answer')
      .connect('generate-answer', 'suggest-followup')
      .connect('generate-summary', 'final-result')
      .connect('generate-answer', 'final-result')
      .connect('final-result', 'end');

    return builder.build();
  },
};
