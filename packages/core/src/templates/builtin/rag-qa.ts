/**
 * RAG Q&A Template
 */

import { createWorkflow } from '../../builder/index.js';
import type { WorkflowTemplate } from '../types.js';

export const ragQATemplate: WorkflowTemplate = {
  metadata: {
    id: 'rag-qa',
    name: 'çŸ¥è¯†åº“é—®ç­”',
    description: 'åŸºäºçŸ¥è¯†åº“æ£€ç´¢çš„é—®ç­”ç³»ç»Ÿï¼Œå…ˆæ£€ç´¢ç›¸å…³æ–‡æ¡£å†ç”Ÿæˆå›ç­”',
    category: 'rag',
    tags: ['RAG', 'çŸ¥è¯†åº“', 'é—®ç­”', 'æ£€ç´¢'],
    keywords: [
      'çŸ¥è¯†åº“', 'æ–‡æ¡£', 'æ£€ç´¢', 'RAG', 'çŸ¥è¯†é—®ç­”', 'æ–‡æ¡£é—®ç­”',
      'èµ„æ–™åº“', 'æ•°æ®åº“', 'knowledge', 'retrieval', 'æŸ¥è¯¢æ–‡æ¡£',
    ],
    nodeTypes: ['start', 'knowledge-retrieval', 'llm', 'end'],
    complexity: 2,
  },

  build: (params = {}) => {
    const datasetIds = (params['datasetIds'] as string[]) ?? ['your-dataset-id'];
    const topK = (params['topK'] as number) ?? 5;
    const scoreThreshold = (params['scoreThreshold'] as number) ?? 0.5;
    const model = (params['model'] as string) ?? 'gpt-4o';
    const provider = (params['provider'] as string) ?? 'openai';
    const systemPrompt = (params['systemPrompt'] as string) ??
      `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å®¢æœåŠ©æ‰‹ã€‚è¯·æ ¹æ®æä¾›çš„å‚è€ƒèµ„æ–™å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

è¦æ±‚ï¼š
1. åªæ ¹æ®å‚è€ƒèµ„æ–™ä¸­çš„ä¿¡æ¯å›ç­”ï¼Œä¸è¦ç¼–é€ 
2. å¦‚æœå‚è€ƒèµ„æ–™ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯šå®åœ°è¯´"æˆ‘æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
3. å›ç­”è¦ç®€æ´æ˜äº†
4. å¦‚æœéœ€è¦ï¼Œå¯ä»¥å¼•ç”¨èµ„æ–™ä¸­çš„å…·ä½“å†…å®¹`;

    return createWorkflow({
      name: 'çŸ¥è¯†åº“é—®ç­”',
      description: 'åŸºäºçŸ¥è¯†åº“çš„ RAG é—®ç­”ç³»ç»Ÿ',
      icon: 'ğŸ“š',
    })
      .addStart({
        variables: [
          {
            name: 'query',
            label: 'é—®é¢˜',
            type: 'paragraph',
            required: true,
            maxLength: 2000,
          },
        ],
      })
      .addKnowledgeRetrieval({
        id: 'retrieval',
        title: 'çŸ¥è¯†æ£€ç´¢',
        queryFrom: ['start', 'query'],
        datasetIds,
        topK,
        scoreThreshold,
        rerankingEnabled: true,
        rerankingModel: {
          provider: 'cohere',
          model: 'rerank-multilingual-v2.0',
        },
      })
      .addLLM({
        id: 'llm',
        title: 'ç”Ÿæˆå›ç­”',
        provider,
        model,
        temperature: 0.5,
        systemPrompt,
        userPrompt: '{{#start.query#}}',
        context: {
          enabled: true,
          variableSelector: ['retrieval', 'result'],
        },
      })
      .addEnd({
        id: 'end',
        outputs: [
          { name: 'answer', source: ['llm', 'text'] },
        ],
      })
      .connect('start', 'retrieval')
      .connect('retrieval', 'llm')
      .connect('llm', 'end')
      .build();
  },
};
