/**
 * Conditional Workflow Template
 */

import { createWorkflow } from '../../builder/index.js';
import type { WorkflowTemplate } from '../types.js';

export const conditionalTemplate: WorkflowTemplate = {
  metadata: {
    id: 'conditional',
    name: 'æ¡ä»¶åˆ†æ”¯',
    description: 'æ ¹æ®æ¡ä»¶åˆ¤æ–­æ‰§è¡Œä¸åŒçš„å¤„ç†é€»è¾‘',
    category: 'automation',
    tags: ['æ¡ä»¶', 'åˆ†æ”¯', 'IF/ELSE', 'é€»è¾‘'],
    keywords: [
      'æ¡ä»¶', 'åˆ¤æ–­', 'if', 'else', 'åˆ†æ”¯', 'é€»è¾‘',
      'ä¸åŒå¤„ç†', 'é€‰æ‹©', 'å†³ç­–',
    ],
    nodeTypes: ['start', 'if-else', 'llm', 'variable-aggregator', 'end'],
    complexity: 2,
  },

  build: (params = {}) => {
    const model = (params['model'] as string) ?? 'gpt-4o';
    const provider = (params['provider'] as string) ?? 'openai';

    return createWorkflow({
      name: 'æ¡ä»¶åˆ†æ”¯',
      description: 'æ ¹æ®æ¡ä»¶åˆ¤æ–­æ‰§è¡Œä¸åŒçš„å¤„ç†é€»è¾‘',
      icon: 'ğŸ”€',
    })
      .addStart({
        variables: [
          {
            name: 'input',
            label: 'è¾“å…¥å†…å®¹',
            type: 'paragraph',
            required: true,
            maxLength: 5000,
          },
          {
            name: 'mode',
            label: 'å¤„ç†æ¨¡å¼',
            type: 'select',
            required: true,
            options: ['è¯¦ç»†', 'ç®€æ´'],
            default: 'ç®€æ´',
          },
        ],
      })
      .addIfElse({
        id: 'condition',
        title: 'æ£€æŸ¥æ¨¡å¼',
        conditions: [
          {
            id: 'detailed',
            logicalOperator: 'and',
            rules: [
              {
                variableSelector: ['start', 'mode'],
                operator: '=',
                value: 'è¯¦ç»†',
              },
            ],
          },
        ],
      })
      .addLLM({
        id: 'llm-detailed',
        title: 'è¯¦ç»†å¤„ç†',
        provider,
        model,
        temperature: 0.7,
        maxTokens: 4000,
        systemPrompt: 'è¯·å¯¹ç”¨æˆ·è¾“å…¥è¿›è¡Œè¯¦ç»†åˆ†æå’Œå¤„ç†ï¼Œæä¾›å…¨é¢çš„å›å¤ã€‚',
        userPrompt: '{{#start.input#}}',
      })
      .addLLM({
        id: 'llm-brief',
        title: 'ç®€æ´å¤„ç†',
        provider,
        model,
        temperature: 0.5,
        maxTokens: 1000,
        systemPrompt: 'è¯·å¯¹ç”¨æˆ·è¾“å…¥è¿›è¡Œç®€æ´å¤„ç†ï¼Œåªæä¾›æ ¸å¿ƒè¦ç‚¹ã€‚',
        userPrompt: '{{#start.input#}}',
      })
      .addAggregator({
        id: 'aggregator',
        title: 'ç»“æœèšåˆ',
        variables: [
          ['llm-detailed', 'text'],
          ['llm-brief', 'text'],
        ],
        outputType: 'string',
      })
      .addEnd({
        id: 'end',
        outputs: [{ name: 'result', source: ['aggregator', 'output'] }],
      })
      // è¿æ¥
      .connect('start', 'condition')
      .connect('condition', 'llm-detailed', { sourceHandle: 'detailed' })
      .connect('condition', 'llm-brief', { sourceHandle: 'false' })
      .connect('llm-detailed', 'aggregator')
      .connect('llm-brief', 'aggregator')
      .connect('aggregator', 'end')
      .build();
  },
};
