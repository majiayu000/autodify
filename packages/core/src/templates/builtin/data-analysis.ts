/**
 * Data Analysis Template
 */

import { createWorkflow } from '../../builder/index.js';
import type { WorkflowTemplate } from '../types.js';

export const dataAnalysisTemplate: WorkflowTemplate = {
  metadata: {
    id: 'data-analysis',
    name: 'æ•°æ®åˆ†æåŠ©æ‰‹',
    description: 'ä½¿ç”¨ Python ä»£ç è¿›è¡Œæ•°æ®åˆ†æï¼ŒåŒ…å«æ•°æ®é¢„å¤„ç†ã€åˆ†æå’Œå¯è§†åŒ–',
    category: 'analysis',
    tags: ['æ•°æ®åˆ†æ', 'Python', 'å¯è§†åŒ–', 'ç»Ÿè®¡'],
    keywords: [
      'æ•°æ®åˆ†æ', 'æ•°æ®å¤„ç†', 'ç»Ÿè®¡', 'å¯è§†åŒ–', 'python',
      'data analysis', 'statistics', 'visualization', 'pandas',
      'åˆ†ææ•°æ®', 'æ•°æ®ç»Ÿè®¡', 'å›¾è¡¨',
    ],
    nodeTypes: ['start', 'code', 'llm', 'if-else', 'end'],
    complexity: 3,
  },

  build: (params = {}) => {
    const model = (params['model'] as string) ?? 'gpt-4o';
    const provider = (params['provider'] as string) ?? 'openai';
    const allowedLibraries = (params['allowedLibraries'] as string[]) ?? [
      'pandas',
      'numpy',
      'matplotlib',
      'seaborn',
      'scipy',
      'sklearn',
    ];

    return createWorkflow({
      name: 'æ•°æ®åˆ†æåŠ©æ‰‹',
      description: 'è‡ªåŠ¨åŒ–æ•°æ®åˆ†æå’Œå¯è§†åŒ–å·¥ä½œæµ',
      icon: 'ğŸ“Š',
    })
      .addStart({
        variables: [
          {
            name: 'analysis_request',
            label: 'åˆ†æéœ€æ±‚',
            type: 'paragraph',
            required: true,
            maxLength: 2000,
          },
          {
            name: 'data',
            label: 'æ•°æ®ï¼ˆCSV/JSON æ ¼å¼ï¼‰',
            type: 'paragraph',
            required: true,
            maxLength: 50000,
          },
        ],
      })
      // åˆ†æéœ€æ±‚ç†è§£
      .addLLM({
        id: 'understand-request',
        title: 'ç†è§£åˆ†æéœ€æ±‚',
        provider,
        model,
        temperature: 0.3,
        systemPrompt: `ä½ æ˜¯æ•°æ®åˆ†æä¸“å®¶ã€‚åˆ†æç”¨æˆ·çš„éœ€æ±‚ï¼Œè¾“å‡ºç»“æ„åŒ–çš„åˆ†æè®¡åˆ’ã€‚

è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰ï¼š
{
  "analysis_type": "æè¿°æ€§ç»Ÿè®¡/ç›¸å…³æ€§åˆ†æ/è¶‹åŠ¿åˆ†æ/åˆ†ç±»é¢„æµ‹ç­‰",
  "key_metrics": ["æŒ‡æ ‡1", "æŒ‡æ ‡2"],
  "visualization_needed": true/false,
  "steps": ["æ­¥éª¤1", "æ­¥éª¤2"]
}`,
        userPrompt: 'åˆ†æéœ€æ±‚ï¼š{{#start.analysis_request#}}',
      })
      // ç”Ÿæˆåˆ†æä»£ç 
      .addLLM({
        id: 'generate-code',
        title: 'ç”Ÿæˆåˆ†æä»£ç ',
        provider,
        model,
        temperature: 0.2,
        systemPrompt: `ä½ æ˜¯ Python æ•°æ®åˆ†æä¸“å®¶ã€‚æ ¹æ®åˆ†æè®¡åˆ’ç”Ÿæˆå®Œæ•´çš„ Python ä»£ç ã€‚

è¦æ±‚ï¼š
1. ä½¿ç”¨ pandas, numpy ç­‰æ ‡å‡†åº“
2. åŒ…å«æ•°æ®é¢„å¤„ç†ï¼ˆç¼ºå¤±å€¼å¤„ç†ã€å¼‚å¸¸å€¼æ£€æµ‹ï¼‰
3. è¿›è¡Œæ‰€éœ€çš„ç»Ÿè®¡åˆ†æ
4. å¦‚éœ€å¯è§†åŒ–ï¼Œä½¿ç”¨ matplotlib æˆ– seaborn
5. ä»£ç è¦æœ‰è¯¦ç»†æ³¨é‡Š
6. æœ€åæ‰“å°åˆ†æç»“æœ

å¯ç”¨åº“ï¼š${allowedLibraries.join(', ')}

åªè¾“å‡º Python ä»£ç ï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚`,
        userPrompt: `åˆ†æè®¡åˆ’ï¼š{{#understand-request.text#}}

æ•°æ®é¢„è§ˆï¼š
{{#start.data#}}`,
      })
      // æ‰§è¡Œä»£ç 
      .addCode({
        id: 'execute-analysis',
        title: 'æ‰§è¡Œæ•°æ®åˆ†æ',
        language: 'python3',
        code: '{{#generate-code.text#}}',
        inputs: [
          { name: 'data', source: ['start', 'data'] },
        ],
        outputs: [
          { name: 'result', type: 'object' },
        ],
      })
      // æ£€æŸ¥æ‰§è¡Œç»“æœ
      .addIfElse({
        id: 'check-result',
        title: 'æ£€æŸ¥æ‰§è¡Œç»“æœ',
        conditions: [
          {
            id: 'success',
            logicalOperator: 'and',
            rules: [
              {
                variableSelector: ['execute-analysis', 'result'],
                operator: 'is not empty',
                value: '',
              },
            ],
          },
        ],
      })
      // æˆåŠŸï¼šç”Ÿæˆåˆ†ææŠ¥å‘Š
      .addLLM({
        id: 'generate-report',
        title: 'ç”Ÿæˆåˆ†ææŠ¥å‘Š',
        provider,
        model,
        temperature: 0.5,
        systemPrompt: `ä½ æ˜¯æ•°æ®åˆ†æå¸ˆã€‚æ ¹æ®ä»£ç æ‰§è¡Œç»“æœï¼Œç”Ÿæˆæ˜“æ‡‚çš„åˆ†ææŠ¥å‘Šã€‚

æŠ¥å‘Šåº”åŒ…æ‹¬ï¼š
1. æ•°æ®æ¦‚å†µ
2. å…³é”®å‘ç°
3. ç»Ÿè®¡ç»“æœè§£è¯»
4. å»ºè®®å’Œæ´å¯Ÿ

ä½¿ç”¨ Markdown æ ¼å¼ï¼Œç»“æ„æ¸…æ™°ã€‚`,
        userPrompt: `åŸå§‹éœ€æ±‚ï¼š{{#start.analysis_request#}}

åˆ†æè®¡åˆ’ï¼š{{#understand-request.text#}}

æ‰§è¡Œç»“æœï¼š
{{#execute-analysis.result#}}`,
      })
      // å¤±è´¥ï¼šé”™è¯¯åˆ†æ
      .addLLM({
        id: 'analyze-error',
        title: 'é”™è¯¯åˆ†æ',
        provider,
        model,
        temperature: 0.3,
        systemPrompt: 'ä½ æ˜¯ Python ä¸“å®¶ã€‚åˆ†æä»£ç æ‰§è¡Œé”™è¯¯ï¼Œæä¾›è§£å†³å»ºè®®ã€‚',
        userPrompt: `ä»£ç ï¼š
{{#generate-code.text#}}

é”™è¯¯ä¿¡æ¯ï¼šä»£ç æ‰§è¡Œå¤±è´¥

è¯·è¯´æ˜å¯èƒ½çš„é—®é¢˜åŸå› å’Œè§£å†³æ–¹æ¡ˆã€‚`,
      })
      // èšåˆç»“æœ
      .addAggregator({
        id: 'result-aggregator',
        title: 'ç»“æœèšåˆ',
        variables: [
          ['generate-report', 'text'],
          ['analyze-error', 'text'],
        ],
        outputType: 'string',
      })
      .addEnd({
        id: 'end',
        outputs: [
          { name: 'report', source: ['result-aggregator', 'output'] },
          { name: 'code', source: ['generate-code', 'text'] },
          { name: 'execution_result', source: ['execute-analysis', 'result'] },
        ],
      })
      .connect('start', 'understand-request')
      .connect('understand-request', 'generate-code')
      .connect('generate-code', 'execute-analysis')
      .connect('execute-analysis', 'check-result')
      .connect('check-result', 'generate-report', { sourceHandle: 'true' })
      .connect('check-result', 'analyze-error', { sourceHandle: 'false' })
      .connect('generate-report', 'result-aggregator')
      .connect('analyze-error', 'result-aggregator')
      .connect('result-aggregator', 'end')
      .build();
  },
};
