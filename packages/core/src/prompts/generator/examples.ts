/**
 * Generator Example Workflows
 */

/**
 * ç®€å•å·¥ä½œæµç¤ºä¾‹
 */
export const SIMPLE_WORKFLOW_EXAMPLE = `# ç¤ºä¾‹ï¼šç®€å•é—®ç­”å·¥ä½œæµ

ç”¨æˆ·è¯·æ±‚ï¼š"åˆ›å»ºä¸€ä¸ªç®€å•çš„é—®ç­”å·¥ä½œæµ"

è¾“å‡ºï¼š
\`\`\`yaml
app:
  description: ç®€å•çš„ AI é—®ç­”å·¥ä½œæµ
  icon: ğŸ’¬
  icon_background: "#FFEAD5"
  mode: workflow
  name: ç®€å•é—®ç­”
  use_icon_as_answer_icon: false
kind: app
version: 0.1.3
workflow:
  conversation_variables: []
  environment_variables: []
  features:
    file_upload:
      enabled: false
      image:
        enabled: false
        number_limits: 3
        transfer_methods:
          - local_file
          - remote_url
    opening_statement: ""
    retriever_resource:
      enabled: true
    sensitive_word_avoidance:
      enabled: false
    speech_to_text:
      enabled: false
    suggested_questions: []
    suggested_questions_after_answer:
      enabled: false
    text_to_speech:
      enabled: false
      language: ""
      voice: ""
  graph:
    edges:
      - data:
          isInIteration: false
          sourceType: start
          targetType: llm
        id: start-source-llm-target
        source: start
        sourceHandle: source
        target: llm
        targetHandle: target
        type: custom
        zIndex: 0
      - data:
          isInIteration: false
          sourceType: llm
          targetType: end
        id: llm-source-end-target
        source: llm
        sourceHandle: source
        target: end
        targetHandle: target
        type: custom
        zIndex: 0
    nodes:
      - data:
          desc: ""
          selected: false
          title: å¼€å§‹
          type: start
          variables:
            - label: é—®é¢˜
              max_length: 2000
              options: []
              required: true
              type: paragraph
              variable: question
        id: start
        type: custom
      - data:
          context:
            enabled: false
            variable_selector: []
          desc: ""
          model:
            completion_params:
              temperature: 0.7
            mode: chat
            name: gpt-4o
            provider: openai
          prompt_template:
            - role: system
              text: ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„ AI åŠ©æ‰‹ã€‚è¯·ç®€æ´å‡†ç¡®åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
            - role: user
              text: "{{#start.question#}}"
          selected: false
          title: AI å›ç­”
          type: llm
          vision:
            enabled: false
        id: llm
        type: custom
      - data:
          desc: ""
          outputs:
            - value_selector:
                - llm
                - text
              variable: answer
          selected: false
          title: ç»“æŸ
          type: end
        id: end
        type: custom
    viewport:
      x: 0
      y: 0
      zoom: 1
\`\`\``;

/**
 * ç¿»è¯‘å·¥ä½œæµç¤ºä¾‹
 */
export const TRANSLATION_WORKFLOW_EXAMPLE = `# ç¤ºä¾‹ï¼šç¿»è¯‘å·¥ä½œæµ

ç”¨æˆ·è¯·æ±‚ï¼š"åˆ›å»ºä¸€ä¸ªä¸­è‹±äº’è¯‘çš„å·¥ä½œæµ"

è¾“å‡ºï¼š
\`\`\`yaml
app:
  description: æ™ºèƒ½ä¸­è‹±æ–‡äº’è¯‘å·¥å…·
  icon: ğŸŒ
  icon_background: "#FFEAD5"
  mode: workflow
  name: ä¸­è‹±äº’è¯‘
  use_icon_as_answer_icon: false
kind: app
version: 0.1.3
workflow:
  conversation_variables: []
  environment_variables: []
  features:
    file_upload:
      enabled: false
      image:
        enabled: false
        number_limits: 3
        transfer_methods:
          - local_file
          - remote_url
    opening_statement: ""
    retriever_resource:
      enabled: true
    sensitive_word_avoidance:
      enabled: false
    speech_to_text:
      enabled: false
    suggested_questions: []
    suggested_questions_after_answer:
      enabled: false
    text_to_speech:
      enabled: false
      language: ""
      voice: ""
  graph:
    edges:
      - data:
          isInIteration: false
          sourceType: start
          targetType: llm
        id: start-source-llm-target
        source: start
        sourceHandle: source
        target: llm
        targetHandle: target
        type: custom
        zIndex: 0
      - data:
          isInIteration: false
          sourceType: llm
          targetType: end
        id: llm-source-end-target
        source: llm
        sourceHandle: source
        target: end
        targetHandle: target
        type: custom
        zIndex: 0
    nodes:
      - data:
          desc: ""
          selected: false
          title: å¼€å§‹
          type: start
          variables:
            - label: å¾…ç¿»è¯‘æ–‡æœ¬
              max_length: 5000
              options: []
              required: true
              type: paragraph
              variable: text
        id: start
        type: custom
      - data:
          context:
            enabled: false
            variable_selector: []
          desc: ""
          model:
            completion_params:
              temperature: 0.3
            mode: chat
            name: gpt-4o
            provider: openai
          prompt_template:
            - role: system
              text: |
                ä½ æ˜¯ä¸“ä¸šç¿»è¯‘ã€‚è¯·åˆ¤æ–­è¾“å…¥æ–‡æœ¬çš„è¯­è¨€ï¼š
                - å¦‚æœæ˜¯ä¸­æ–‡ï¼Œç¿»è¯‘æˆè‹±æ–‡
                - å¦‚æœæ˜¯è‹±æ–‡ï¼Œç¿»è¯‘æˆä¸­æ–‡
                - å¦‚æœæ˜¯å…¶ä»–è¯­è¨€ï¼Œç¿»è¯‘æˆä¸­æ–‡

                åªè¾“å‡ºç¿»è¯‘ç»“æœï¼Œä¸è¦è§£é‡Šã€‚
            - role: user
              text: "{{#start.text#}}"
          selected: false
          title: ç¿»è¯‘
          type: llm
          vision:
            enabled: false
        id: llm
        type: custom
      - data:
          desc: ""
          outputs:
            - value_selector:
                - llm
                - text
              variable: translation
          selected: false
          title: è¾“å‡º
          type: end
        id: end
        type: custom
    viewport:
      x: 0
      y: 0
      zoom: 1
\`\`\``;

/**
 * è·å–æ‰€æœ‰ç¤ºä¾‹
 */
export function getAllExamples(): string {
  return `${SIMPLE_WORKFLOW_EXAMPLE}

${TRANSLATION_WORKFLOW_EXAMPLE}`;
}
